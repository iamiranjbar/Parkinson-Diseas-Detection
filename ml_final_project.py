# -*- coding: utf-8 -*-
"""ML_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cEy8i07fbUF1ILrjN5a28ugQxNyc1S3a

# Machine Learning Final Project

#### Bahar Bateni (810199326)
#### Amir Ranjbar (810199340)
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

"""## Pre-processing

The first step is to pre-process the data. We can think of three types of pre-processing:


1.   Normalization
2.   Balancing classes
3.   Dimension Reduction

But before starting any of these, we need to read the data from the given CSV file and break it into train and test data.
"""

data = pd.read_csv('pd_speech_features.csv') 
data.head()

data = data.drop(columns=['id'])
shuffled_data = data.sample(frac=1, random_state=0)
train = shuffled_data[:int(len(data) * 0.9)]
test = shuffled_data[int(len(data) * 0.9):]
print('train number: {}, test number: {}'.format(len(train), len(test)))

y_train = train['class'].to_numpy()
X_train = train.drop(columns=['class'])
y_test = test['class'].to_numpy()
X_test = test.drop(columns=['class'])

"""### Normalization

For normalization, we use Scikit Learn's MinMaxScaler. We can normalize with something more complex, such as L1 or L2 normalizers as well.
"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

print(X_train[:10])

"""### Imbalance Dataset

The given dataset is imbalance, meaning that the number of datapoints of different classes are significantly different. In cases like this, we may encounter the accuracy paradox, meaning that while the accuracy may get very high, the actual performance may not be any good. For example, it may classify all the datapoint as the major class and still gets a high accuracy.

One remedy for this problem is using other metrics in addition to accuracy. For example, the Confusion Matrix can show were exactly we classified wrong, and which class we wrongly classified as which. This helps us find out if the classifier is biased toward classifying as the majority class. Also Precision, Recall and F1 Score (that can all be calculated from the Confusion Matrix) are all metrics that can help in this regard. Plotting the ROC curve is also useful.

Another solution can be resampling the dataset. The balancing process can be done either by copying some samples from the minority class, or deleting some from the majority class. Both of these solutions have their own advantages and disadvantages.

This problem can also be approached by generating synthetic samples instead of resampling. This can be done by randomly sampling the attributes from datapoints in the minority class. We can, for example, use Naive Bayes to sample each attribute independently. (One widly used technique for generating samples is Synthetic Minority Oversampling Technique (SMOTE)). In this approach, we can generate new samples that are different from the existing ones, but the non-linear relationship between the samples may not be preserved. For example, if features are correlated, sampling them independently may create unreal or wrong datapoints

In addition to that, we can use algorithms that work better with the imbalance data (like decision trees) or change the cost function so that we penaltize misclassifying the minority class more. As the methods and algorithms used in this problem are specified, this approach does not suit our needs.

When the difference in the sizes of classes is huge, for example when trying to detect fraud, it may be better to change our prespective to the problem and use methods of anomaly detection instead of classification.

In conclusion, as we can't change the classification methods, and we don't want to generate improper datapoints (because we have lots of features, many of them correlated), we should either resample the data or use more metrics. Resampling has its own problems, becuase undersampling the majority class, we may risk losing some important informations that significantly decreases the machine performance because of lack of samples to train on. On the other hand, when oversampling the minority class, we might cause underfitting.

That being the case, we chose to handle the problem of having an imbalance dataset by checking additional metrics (other than accuracy) that can show how well our model is performing.

## Dimension Reduction

In this section, we try different methods of dimension reduction to remove redundant/correlated features or combining feature and create new good feature, thus increasing the performance and accuracy metrics of our model while decreasing the execution time.
"""

print(X_train.shape, X_test.shape)

"""### LDA (Linear Discriminant Analysis)"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

def LDA(X_train, y_train, X_test):
  lda = LinearDiscriminantAnalysis()
  lda.fit(X_train, y_train)
  reduced_X_train = lda.transform(X_train)
  reduced_X_test = lda.transform(X_test)
  return reduced_X_train, reduced_X_test

LDA_reduced_X_train, LDA_reduced_X_test = LDA(X_train, y_train, X_test)
print(LDA_reduced_X_train.shape, LDA_reduced_X_test.shape)

"""### ICA"""

from sklearn.decomposition import FastICA

def ICA(feature_count, X_train, y_train, X_test):
  ica = FastICA(n_components=feature_count, random_state=0)
  ica.fit(X_train, y_train)
  reduced_X_train = ica.transform(X_train)
  reduced_X_test = ica.transform(X_test)
  return reduced_X_train, reduced_X_test

ICA_reduced_X_train, ICA_reduced_X_test = ICA(80, X_train, y_train, X_test)
print(ICA_reduced_X_train.shape, ICA_reduced_X_test.shape)

"""### Finding Number of PCs"""

import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components=100)
X = data.drop(columns=['class'])
y = data['class'].to_numpy()
scaler = MinMaxScaler()
scaler.fit(X)
X = scaler.transform(X)
pca.fit(X, y)
xs = np.array(range(1,101))
plt.figure()
plt.figure(figsize=(8,7))
plt.xticks(fontsize=12)
plt.yticks(fontsize=14)
plt.plot(xs, pca.explained_variance_ratio_)
plt.xlabel('Principal Component',fontsize=15)
plt.ylabel('Covered Variance by this PC',fontsize=15)
plt.title("Explained variation per principal component",fontsize=20)
plt.show()
print('Explained variation per principal component for the first ten PCs: {}'.format(pca.explained_variance_ratio_[0:20]))
print(sum(pca.explained_variance_ratio_[0:80]))

"""### PCA (Principal Component Analysis) with whitening"""

from sklearn.decomposition import PCA

def PCA_W(X_train, y_train, X_test):
  pca = PCA(n_components=80, random_state=0, whiten=True)
  pca.fit(X_train, y_train)
  reduced_X_train = pca.transform(X_train)
  reduced_X_test = pca.transform(X_test)
  return reduced_X_train, reduced_X_test

PCA_W_reduced_X_train, PCA_W_reduced_X_test = PCA_W(X_train, y_train, X_test)
print(PCA_W_reduced_X_train.shape, PCA_W_reduced_X_test.shape)

"""### PCA (Principal Component Analysis) without withening"""

from sklearn.decomposition import PCA

def PCA_N_W(X_train, y_train, X_test):
  pca = PCA(n_components=80, random_state=0, whiten=False)
  pca.fit(X_train, y_train)
  reduced_X_train = pca.transform(X_train)
  reduced_X_test = pca.transform(X_test)
  return reduced_X_train, reduced_X_test

PCA_N_W_reduced_X_train, PCA_N_W_reduced_X_test = PCA_W(X_train, y_train, X_test)
print(PCA_N_W_reduced_X_train.shape, PCA_N_W_reduced_X_test.shape)

"""### Sequential Backward Feature Elimination (with SVR as model)"""

from sklearn.feature_selection import RFE
from sklearn.svm import SVR

def SBFE(X_train, y_train, X_test, classifier=SVR(kernel="linear")):
  sfs = RFE(classifier, n_features_to_select=10)
  sfs.fit(X_train, y_train)
  reduced_X_train = sfs.transform(X_train)
  reduced_X_test = sfs.transform(X_test)
  return reduced_X_train, reduced_X_test

SBFE_reduced_X_train, SBFE_reduced_X_test = SBFE(X_train, y_train, X_test)
print(SBFE_reduced_X_train.shape, SBFE_reduced_X_test.shape)

"""### Autoencoders"""

import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Dense, Input

def AutoEncoder(X_train, y_train, X_test):
  encoding_dim = 10

  input_data = Input(shape=(X_train.shape[1],))
  # mid_encode = Dense(len(X_train[0]), activation='relu')(input_data)
  encoded = Dense(encoding_dim, activation='relu')(input_data)
  decoded = Dense(X_train.shape[1], activation='sigmoid')(encoded)
  autoencoder = Model(input_data, decoded)
  autoencoder.compile(optimizer='adam',
                      loss='binary_crossentropy')
  
  hist_auto = autoencoder.fit(X_train, X_train,
                  epochs=50,
                  # batch_size=4,
                  # batch_size=256,
                  batch_size=8,
                  shuffle=True,
                  validation_split=0.1)

  plt.figure()
  plt.plot(hist_auto.history['loss'])
  plt.plot(hist_auto.history['val_loss'])
  plt.title('Autoencoder loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='upper right')
  plt.show()

  encoder = Model(input_data, encoded)
  encoded_input = Input(shape=(encoding_dim,))
  decoder_layer = autoencoder.layers[-1]
  decoder = Model(encoded_input, decoder_layer(encoded_input))

  encoded_X_train = encoder.predict(X_train)
  encoded_X_test = encoder.predict(X_test)
  return encoded_X_train, encoded_X_test

AE_reduced_X_train, AE_reduced_X_test = AutoEncoder(X_train, y_train, X_test)
print(AE_reduced_X_train.shape, AE_reduced_X_test.shape)

"""## Evaluation Metrics
1. Accuracy
2. Confusion Matrix
3. ROC Curve
4. Area Under Curve(AUC)
5. F1 Score
"""

from sklearn.metrics import accuracy_score, confusion_matrix, plot_roc_curve, \
                            roc_auc_score, f1_score, roc_curve

def evaluate_model(model_clf_predictor, X_train, y_train, X_test, y_test, is_clf=True):
  model_clf, predicted_y = model_clf_predictor(X_train, y_train, X_test)
  true_y = list(y_test)
  accuracy = accuracy_score(true_y, predicted_y)
  print("Accuracy: {}".format(accuracy))
  conf_matrix = confusion_matrix(true_y, predicted_y)
  print("Confusion Matrix:")
  print(conf_matrix)
  if is_clf:
    print("ROC Curve:")
    plot_roc_curve(model_clf, X_test, y_test)
    plt.show()
    auc = roc_auc_score(y_test, model_clf.predict_proba(X_test)[:, 1])
    print("AUC: {}".format(auc))
  else:
    print("ROC Curve:")
    tp, fp, thresholds = roc_curve(y_test, predicted_y)
    plt.plot(tp, fp)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.show()
    auc = roc_auc_score(y_test, predicted_y)
    print("AUC: {}".format(auc))
  f1 = f1_score(true_y, predicted_y, average='binary')
  print("F1 Score: {}".format(f1))
  print("______________________________")

def evaluate_model_with_lda(model_clf_predictor, is_clf=True):
  print("Feature reduction by LDA")
  evaluate_model(model_clf_predictor, LDA_reduced_X_train, y_train, 
                 LDA_reduced_X_test, y_test, is_clf)

def evaluate_model_with_ica(model_clf_predictor, is_clf=True):
  print("Feature reduction by ICA")
  evaluate_model(model_clf_predictor, ICA_reduced_X_train, y_train, 
                 ICA_reduced_X_test, y_test, is_clf)

def evaluate_model_with_white_pca(model_clf_predictor, is_clf=True):
  print("Feature reduction by PCA with Withening")
  evaluate_model(model_clf_predictor, PCA_W_reduced_X_train, y_train, 
                 PCA_W_reduced_X_test, y_test, is_clf)

def evaluate_model_with_regular_pca(model_clf_predictor, is_clf=True):
  print("Feature reduction by PCA without withening")
  evaluate_model(model_clf_predictor, PCA_N_W_reduced_X_train, y_train, 
                 PCA_N_W_reduced_X_test, y_test, is_clf)

def evaluate_model_with_sbfe(model_clf_predictor, is_clf=True):
  print("Feature reduction by Sequential Backward Feature Elimination")
  evaluate_model(model_clf_predictor, SBFE_reduced_X_train, y_train, 
                 SBFE_reduced_X_test, y_test, is_clf)

def evaluate_model_with_autoencoders(model_clf_predictor, is_clf=True):
  print("Feature reduction by AutoEncoders")
  evaluate_model(model_clf_predictor, AE_reduced_X_train, y_train, 
                 AE_reduced_X_test, y_test, is_clf)

"""### K-Fold Cross Validation"""

from sklearn.model_selection import KFold

def k_fold_cross_validation(dimension_reduction, model_predictor):
  kfold = KFold(5, True, 1)
  accuracies = []
  for train, test in kfold.split(data):
    train_data = data.iloc[train, :]
    test_data = data.iloc[test, :]
    y_train = train_data['class'].to_numpy()
    X_train = train_data.drop(columns=['class'])
    y_test = test_data['class'].to_numpy()
    X_test = test_data.drop(columns=['class'])
    X_train = scaler.transform(X_train)
    X_test = scaler.transform(X_test)
    reduced_X_train, reduced_X_test = dimension_reduction(X_train, y_train, X_test)
    _, predicted_y = model_predictor(reduced_X_train, y_train, reduced_X_test)
    true_y = list(y_test)
    accuracy = accuracy_score(true_y, predicted_y)
    accuracies.append(accuracy)
  print("Accuracies Mean: {}".format(np.mean(accuracies)))
  print("Accuracies std: {}".format(np.std(accuracies)))

"""## Classificaiton methods

### Generative Classifiers

#### Bayes classifier with Parzen Window for probability density
"""

import math
from sklearn.neighbors import KernelDensity

def get_parzen_prob_log(train_samples, test_samples):
  parzen = KernelDensity()
  parzen.fit(train_samples)
  return parzen, parzen.score_samples(test_samples)

def Parzen(X_train, y_train, X_test):
  y_train = list(y_train)
  class_0 = [X_train[i] for i in range(len(X_train)) if y_train[i] == 0]
  class_1 = [X_train[i] for i in range(len(X_train)) if y_train[i] == 1]
  prob_1 = sum(y_train)/len(y_train)
  prob_0 = 1 - prob_1
  zero_model, zero_scores = get_parzen_prob_log(class_0, X_test)
  one_model, one_scores = get_parzen_prob_log(class_1, X_test)
  score_0 = zero_scores + [math.log(prob_0)] * len(X_test)
  score_1 = one_scores + [math.log(prob_1)] * len(X_test)
  labels = [1 if score_1[i] > score_0[i] else 0 for i in range(len(X_test))]
  probs = [abs(score_1[i]) / (abs(score_0[i]) + abs(score_1[i])) for i in range(len(X_test))]
  return None, labels

evaluate_model_with_lda(Parzen, False)
evaluate_model_with_ica(Parzen, False)
evaluate_model_with_white_pca(Parzen, False)
evaluate_model_with_regular_pca(Parzen, False)
evaluate_model_with_sbfe(Parzen, False)
evaluate_model_with_autoencoders(Parzen, False)

"""#### Bayes classifier with KNN for probability density"""

from sklearn.neighbors import KNeighborsClassifier

def KNN(X_train, y_train, X_test):
  neigh = KNeighborsClassifier(n_neighbors=3)
  neigh.fit(X_train, y_train)
  return neigh, neigh.predict(X_test)

evaluate_model_with_lda(KNN)
evaluate_model_with_ica(KNN)
evaluate_model_with_white_pca(KNN)
evaluate_model_with_regular_pca(KNN)
evaluate_model_with_sbfe(KNN)
evaluate_model_with_autoencoders(KNN)

"""#### Gaussian Mixture Model (GMM)"""

import math
from sklearn.mixture import GaussianMixture
from scipy.stats import multivariate_normal

def get_gmm_prob(train_samples, test_samples):
  comp_num = 8
  gmm = GaussianMixture(n_components=comp_num, random_state=0)
  gmm.fit(train_samples)
  probabilities = [multivariate_normal.pdf(test_samples, mean=gmm.means_[i], cov=gmm.covariances_[i]) for i in range(comp_num)]
  pred_prob = [0 for _ in probabilities[0]]
  for i in range(comp_num):
      for j in range(len(pred_prob)):
          pred_prob[j] = pred_prob[j] + probabilities[i][j]
  return gmm, pred_prob # Solution?

def GMM(X_train, y_train, X_test):
  class_0 = [X_train[i] for i in range(len(X_train)) if y_train[i] == 0]
  class_1 = [X_train[i] for i in range(len(X_train)) if y_train[i] == 1]
  prob_1 = sum(y_train)/len(y_train)
  prob_0 = 1 - prob_1
  zero_model, zero_score = get_gmm_prob(class_0, X_test)
  one_model, one_score = get_gmm_prob(class_1, X_test)
  score_0 = zero_score + [math.log(prob_0)] * len(X_test)
  score_1 = one_score + [math.log(prob_1)] * len(X_test)
  labels = [1 if score_1[i] > score_0[i] else 0 for i in range(len(X_test))]
  return None, labels

evaluate_model_with_lda(GMM, False)
evaluate_model_with_ica(GMM, False)
evaluate_model_with_white_pca(GMM, False)
evaluate_model_with_regular_pca(GMM, False)
evaluate_model_with_sbfe(GMM, False)
evaluate_model_with_autoencoders(GMM, False)

"""### Discriminative Algorithms

#### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

def LogisticReg(X_train, y_train, X_test):
  logistic_clf = LogisticRegression(random_state=42)
  logistic_clf.fit(X_train, y_train)
  return logistic_clf, logistic_clf.predict(X_test)

evaluate_model_with_lda(LogisticReg)
evaluate_model_with_ica(LogisticReg)
evaluate_model_with_white_pca(LogisticReg)
evaluate_model_with_regular_pca(LogisticReg)
evaluate_model_with_sbfe(LogisticReg)
evaluate_model_with_autoencoders(LogisticReg)

"""#### Support Vector Machine (SVM)"""

from sklearn import svm

def SVMClassifier(X_train, y_train, X_test):
  svm_clf = svm.SVC()
  svm_clf.fit(X_train, y_train)
  return svm, svm_clf.predict(X_test)

evaluate_model_with_lda(SVMClassifier, False)
evaluate_model_with_ica(SVMClassifier, False)
evaluate_model_with_white_pca(SVMClassifier, False)
evaluate_model_with_regular_pca(SVMClassifier, False)
evaluate_model_with_sbfe(SVMClassifier, False)
evaluate_model_with_autoencoders(SVMClassifier, False)

"""#### Decision Tree"""

from sklearn import tree

def DecisionTree(X_train, y_train, X_test):
  decision_tree = tree.DecisionTreeClassifier(random_state=42)
  decision_tree = decision_tree.fit(X_train, y_train)
  return decision_tree, decision_tree.predict(X_test)

evaluate_model_with_lda(DecisionTree)
evaluate_model_with_ica(DecisionTree)
evaluate_model_with_white_pca(DecisionTree)
evaluate_model_with_regular_pca(DecisionTree)
evaluate_model_with_sbfe(DecisionTree)
evaluate_model_with_autoencoders(DecisionTree)

"""#### KNN"""

from sklearn.neighbors import KNeighborsClassifier

def KNN(X_train, y_train, X_test):
  neigh = KNeighborsClassifier(n_neighbors=3)
  neigh.fit(X_train, y_train)
  return neigh, neigh.predict(X_test)

evaluate_model_with_lda(KNN)
evaluate_model_with_ica(KNN)
evaluate_model_with_white_pca(KNN)
evaluate_model_with_regular_pca(KNN)
evaluate_model_with_sbfe(KNN)
evaluate_model_with_autoencoders(KNN)

"""#### Multi-layer Perceptron (MLP)"""

from sklearn.neural_network import MLPClassifier

def MLP(X_train, y_train, X_test):
  mlp_clf = MLPClassifier(random_state=42, max_iter=3000)
  mlp_clf = mlp_clf.fit(X_train, y_train)
  return mlp_clf, mlp_clf.predict(X_test)

evaluate_model_with_lda(MLP)
evaluate_model_with_ica(MLP)
evaluate_model_with_white_pca(MLP)
evaluate_model_with_regular_pca(MLP)
evaluate_model_with_sbfe(MLP)
evaluate_model_with_autoencoders(MLP)

"""#### Radial Basis Function kernel (RBF)"""

from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF

def RBFClassifier(X_train, y_train, X_test):
  kernel = 1.0 * RBF(1.0)
  gpc = GaussianProcessClassifier(kernel=kernel, random_state=42)
  gpc = gpc.fit(X_train, y_train)
  return gpc, gpc.predict(X_test)

evaluate_model_with_lda(RBFClassifier)
evaluate_model_with_ica(RBFClassifier)
evaluate_model_with_white_pca(RBFClassifier)
evaluate_model_with_regular_pca(RBFClassifier)
evaluate_model_with_sbfe(RBFClassifier)
evaluate_model_with_autoencoders(RBFClassifier)

"""## K-Fold Cross validation results on final model"""

k_fold_cross_validation(PCA_W, KNN)

"""## Bagging

### Our implementation of bagging with different classifiers
"""

from random import sample

def BaggingClassifier(X_train, y_train, X_test):
  # fraction = 1.0
  # data = [np.append(X_train[i], y_train[i]) for i in range(len(X_train[0]))]
  # shuffled_train_data = sample(data, round(fraction * len(data)))
  # y_train = [shuffled_train_data[i][-1] for i in range(len(shuffled_train_data))]
  # X_train = [shuffled_train_data[i][:-1] for i in range(len(shuffled_train_data))]
  models = []
  mlp_clf = MLPClassifier(random_state=42, max_iter=3000)
  mlp_clf = mlp_clf.fit(X_train, y_train)
  models.append(mlp_clf)
  neigh = KNeighborsClassifier(n_neighbors=3)
  neigh.fit(X_train, y_train)
  models.append(neigh)
  svm_clf = svm.SVC()
  svm_clf.fit(X_train, y_train)
  models.append(svm_clf)
  predictions = []
  for model in models:
    model_prediction = model.predict(X_test)
    predictions.append(model_prediction)
  final_labels = []
  for index in range(len(X_test)):
    predictions_map = {0: 0, 1: 0}
    for model_index in range(len(models)):
      predictions_map[predictions[model_index][index]] += 1
    if predictions_map[0] > predictions_map[1]:
      final_labels.append(0)
    else:
      final_labels.append(1)
  return None, final_labels

k_fold_cross_validation(PCA_W, BaggingClassifier)

"""### `BaggingClassifier` of `sklearn` (Baggin)

"""

from sklearn.ensemble import BaggingClassifier

def SklearnBaggingClassifier(X_train, y_train, X_test):
  bagging_clf = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),\
                              n_estimators=10, random_state=42).fit(X_train, y_train)
  return bagging_clf, bagging_clf.predict(X_test)

k_fold_cross_validation(PCA_W, SklearnBaggingClassifier)

def DTSklearnBaggingClassifier(X_train, y_train, X_test):
  bagging_clf = BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(),\
                              n_estimators=10, random_state=42).fit(X_train, y_train)
  return bagging_clf, bagging_clf.predict(X_test)

print("Bagging:")
k_fold_cross_validation(PCA_W, DTSklearnBaggingClassifier)
print("Single Decision Tree")
k_fold_cross_validation(PCA_W, DecisionTree)

"""### `GradientBoostingClassifier` of `Sklearn` (Boosting)"""

from sklearn.ensemble import GradientBoostingClassifier

def SklearnBoostingClassifier(X_train, y_train, X_test):
  boosting_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.4,\
                                 max_depth=4, random_state=42).fit(X_train, y_train)
  return boosting_clf, boosting_clf.predict(X_test)

k_fold_cross_validation(PCA_W, SklearnBoostingClassifier)